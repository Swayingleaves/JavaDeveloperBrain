# Collection
## List
### List集合基础
- 实现了Collection接口
- List接口特性：是有序的，元素是可重复的
- 允许元素为null
### 常用的子类
#### Vector
- 底层结构是数组，初始容量为10，每次增长2倍
- 它是线程同步的，已被ArrayList替代
- Vector 也是一个动态数组结构，一个元老级别的类，早在 jdk1.1 就引入进来了，之后在 jdk1.2 里引进 ArrayList，ArrayList 可以说是 Vector 的一个迷你版，ArrayList 大部分的方法和 Vector 比较相似！
- 两者不同的是，Vector 中的方法都加了synchronized，保证操作是线程安全的，但是效率低，而 ArrayList 所有的操作都是非线程安全的，执行效率高，但不安全！
- 对于 Vector，虽然可以在多线程环境下使用，但是在迭代遍历元素的时候依然会报错，抛ConcurrentModificationException异常！
- 在 JDK 中 Vector 已经属于过时的类，官方不建议在程序中采用，如果想要在多线程环境下使用 Vector，建议直接使用并发包中的CopyOnWriteArrayList！
- Stack
  - Stack 是 Vector 的一个子类，本质也是一个动态数组结构，不同的是，它的数据结构是先进后出，取名叫栈！
  - 不过，关于 Java 中 Stack 类，有很多的质疑声，栈更适合用队列结构来实现，这使得 Stack 在设计上不严谨，因此，官方推荐使用 Deque 下的类来是实现栈！
#### LinkedList
- 底层结构是双向链表
- 实现了Deque接口，因此我们可以像操作栈和队列一样操作它
- 线程非同步
- LinkedList 是一个双向链表结构，在任意位置插入、删除都很方便，但是不支持随机取值，每次都只能从一端开始遍历，直到找到查询的对象，然后返回；不过，它不像 ArrayList 那样需要进行内存拷贝，因此相对来说效率较高，但是因为存在额外的前驱和后继节点指针，因此占用的内存比 ArrayList 多一些。
#### ArrayList
- 底层结构是数组，初始容量为10，每次增长1.5倍
  - ArrayList的扩容
    - 原理
      - 调用系统函数的copy方法
      - 一个数组，可以不断地添加元素，而不出现数组下标越界异常。怎么实现？
- 在增删时候，需要数组的拷贝复制(navite 方法由C/C++实现)，性能还是不差的！
- 线程非同步
- ArrayList 是一个动态数组结构，支持随机存取，在指定的位置插入、删除效率低（因为要移动数组元素）；如果内部数组容量不足则自动扩容，扩容系数为原来的1.5倍，因此当数组很大时，效率较低。
- 当然，插入删除也不是效率非常低，在某些场景下，比如尾部插入、删除，因为不需要移动数组元素，所以效率也很高哦！
- ArrayList 是一个非线程安全的类，在多线程环境下使用迭代器遍历元素时，会报错，抛ConcurrentModificationException异常！
  - 迭代器
    - 迭代器删除原始
    - 单线程和多线程的区别
- addAll方法
  - 底层使用native arraycopy方法，内存拷贝数组速度会更快
  - 大数据量时推荐使用，小数据量时与for循环对比不明显
- 如果要从列表的中间添加元素是怎么实现的?
  - 将当前在该位置的元素index（如果有）和任何后续元素向右移动,也是直接使用System.arraycopy
  - arr[index] = data
  - size+1

#### CopyOnWriteArrayList
- 原理：在修改时，复制出一个新数组，修改的操作在新数组中完成，最后将新数组交由array变量指向。
- 写加锁，读不加锁 ReentrantLock
- 缺点：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。
- 适合在读多写少的场景下使用
- iterator
  - 返回一个拷贝数据的对象COWIterator
#### 对比
- ArrayList（动态数组结构），查询快（随意访问或顺序访问），增删慢，但在末尾插入删除，速度与LinkedList相差无几，但是是非线程安全的！
- LinkedList（双向链表结构），查询慢，增删快，也是非线程安全的！
- Vector（动态数组结构），因为方法加了同步锁，相比 ArrayList 执行都慢，基本不在使用，如果需要在多线程下使用，推荐使用并发容器中的CopyOnWriteArrayList来操作，效率高！
- Stack（栈结构）继承于Vector，数据是先进后出，基本不在使用，如果要实现栈，推荐使用 Deque 下的 ArrayDeque，效率比 Stack 高！
`https://juejin.im/post/6844903728324018189`
## Set
### Set集合基础
- 实现了Collection接口
- Set接口特性：无序的，元素不可重复
- 底层大多数是Map结构的实现
- 常用的三个子类都是非同步的
### 常用子类
#### HashSet
- 底层数据结构是哈希表(是一个元素为链表的数组) + 红黑树
- 实际上就是封装了HashMap
- 元素无序，可以为null
#### LinkedHashSet
- 底层数据结构由哈希表(是一个元素为链表的数组)和双向链表组成。
- 父类是HashSet
- 实际上就是LinkHashMap
- 元素可以为null
#### TreeSet
- 底层实际上是一个TreeMap实例(红黑树)
- 可以实现排序的功能
- 元素不能为null
## queue
### 添加
offer，add 区别：
- 一些队列有大小限制，因此如果想在一个满的队列中加入一个新项，多出的项就会被拒绝。
- 这时新的 offer 方法就可以起作用了。它不是对调用 add() 方法抛出一个 unchecked 异常，而只是得到由 offer() 返回的 false。
### 删除
poll，remove 区别：
- remove() 和 poll() 方法都是从队列中删除第一个元素。remove() 的行为与 Collection 接口的版本相似， 但是新的 poll() 方法在用空集合调用时不是抛出异常，只是返回 null。因此新的方法更适合容易出现异常条件的情况。
### 获取
peek，element区别：
- element() 和 peek() 用于在队列的头部查询元素。与 remove() 方法类似，在队列为空时， element() 抛出一个异常，而 peek() 返回 null。
### BlockingQueue
- 插入
  - add(e) 抛出异常
  - offer(e) 特殊值
  - put(e) 阻塞
  - offer(e, time, unit) 超时
- 移除
  - remove() 抛出异常
  - poll() 特殊值
  - take() 阻塞
  - poll(time, unit) 超时
- 获取数据
  - element() 抛出异常
  - peek() 特殊值
### 常见的实现Queue<T> queue = new LinkedList<>();
  
# Map
## Map基础知识
- 存储的结构是key-value键值对，不像Collection是单列集合
- 阅读Map前最好知道什么是散列表和红黑树
## Map常用子类
### HashMap
#### 特点
- k和v允许为null，存储无序
- 非同步
  - HashMap 虽然很强大，但是它是非线程安全的，也就是说，如果在多线程环境下使用，可能因为程序自动扩容操作将单向链表转变成了循环链表，在查询遍历元素的时候，造成程序死循环！此时 CPU 直接会飙到 100%！
    - 如果我们想在多线程环境下使用 HashMap，其中一个推荐的解决办法就是使用 java 并发包下的 ConcurrentHashMap 类！
- 散列表容量大于64且链表大于8时，转成红黑树
  - 为什么是8
    - 源码的注释，根据泊松分布原理发生冲突 并且链表长度为8的概率已经非常小了不到千万分之一
- 底层是散列表+红黑树。初始容量为16，装载因子为0.75，每次扩容2倍
  - `https://mp.weixin.qq.com/s/H6lxTfpedzzDz2QXihhdmw`
  - ![](../img/hashmap/HashMap链表结构.png)

#### 结构
- Node[] table，即哈希桶数组
![](../img/hashmap/HashMapNode代码.png)
- hash冲突使用链地址法
- 参数
  - `int threshold; `            // 扩容阈值
    - `threshold`就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍
  - `final float loadFactor;`    // 负载因子
    - 0.75
  - `transient int modCount;`  // 出现线程问题时，负责及时抛异常
  - `transient int size;`     // HashMap中实际存在的Node数量

#### 初始化
#### 插入
- Key的哈希值会与该值的高16位做异或操作，进一步增加随机性
  ![](../img/hashmap/HashMap-hash方法.png)
  - 按位与运算符（&）
    - 两位同时为“1”，结果才为“1”，否则为0
  - 按位或运算符（|）
    - 参加运算的两个对象只要有一个为1，其值为1。
  - 异或运算符（^）
    - 参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。
- 插入流程
  ![](../img/hashmap/HashMap插入流程.png)
- 插入代码
  ![](../img/hashmap/HashMap插入代码.png)
#### 查找
```java
public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }
    
final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            //检查首节点
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                //判断是否为红黑树
                if (first instanceof TreeNode)
                    //红黑树的查找方式
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                //否则遍历桶
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
```
#### 扩容
![](../img/hashmap/HashMap扩容代码.png)
- jdk1.7多线程扩容死循环问题 https://blog.csdn.net/weixin_39797532/article/details/112337531
  ```java
     void transfer(Entry[] newTable, boolean rehash) {
         int newCapacity = newTable.length;
         // 外层循环遍历数组槽（slot）
         for (Entry<K,V> e : table) {
             // 内层循环遍历单链表
             while(null != e) {
                 // 记录当前节点的next节点
                 Entry<K,V> next = e.next;
                 if (rehash) {
                     e.hash = null == e.key ? 0 : hash(e.key);
                 }
                 // 找到元素在新数组中的槽（slot）
                 int i = indexFor(e.hash, newCapacity);
                 // 用头插法将元素插入新的数组
                 e.next = newTable[i];
                 newTable[i] = e;
                 // 遍历下一个节点
                 e = next;
             }
         }
     }
  ```
  - 在单线程情况下，假设A、B、C三个节点处在一个链表上，扩容后依然处在一个链表上，代码执行过程如下：
    ![](../img/基础/jdk1.7hashmap单线程扩容流程.png)
    - 需要注意的几点是
      - 单链表在转移的过程中会被反转
      - table是线程共享的，而newTable是不共享的
      - 执行table = newTable后，其他线程就可以看到转移线程转移后的结果了
  - 多线程下扩容
    - 其实主要结合这4步，然后结合图示就明白了
      ```java
        Entry<K,V> next = e.next;
        e.next = newTable[i];
        newTable[i] = e;
        e = next;
      ```
    ![](../img/基础/jdk1.7hashmap多线程扩容流程.png)
- jdk1.8的扩容
  ```java
    // 低位链表头节点，尾结点
    // 低位链表就是扩容前后，所处的槽（slot）的下标不变
    // 如果扩容前处于table[n]，扩容后还是处于table[n]
    Node<K,V> loHead = null, loTail = null;
    // 高位链表头节点，尾结点
    // 高位链表就是扩容后所处槽（slot）的下标 = 原来的下标 + 新容量的一半
    // 如果扩容前处于table[n]，扩容后处于table[n + newCapacity / 2]
    Node<K,V> hiHead = null, hiTail = null;
  ```
  ```java
    Node<K,V> next;
    do {
        next = e.next;
        //当前槽上的链表在扩容前和扩容后，所在的槽（slot）下标是否一致
        if ((e.hash & oldCap) == 0) {
            if (loTail == null)
                loHead = e;
            else
                loTail.next = e;
            loTail = e;
        }
        else {
            if (hiTail == null)
                hiHead = e;
            else
                hiTail.next = e;
            hiTail = e;
        }
    } while ((e = next) != null);
    if (loTail != null) {
        loTail.next = null;
        // 低位链表在扩容后，所处槽的下标不变
        newTab[j] = loHead;
    }
    if (hiTail != null) {
        hiTail.next = null;
        // 高位链表在扩容后，所处槽的下标 = 原来的下标 + 扩容前的容量（也就是扩容后容量的一半）
        newTab[j + oldCap] = hiHead;
    }
  ```
  - 等到链表被分成高位链表和低位链表后，再一次性转移到新的table。这样就完成了单链表在扩容过程中的转移，使用两条链表的好处就是转移前后的链表不会倒置，顺序一致则不会因为多线程扩容而导致死循环
- 为什么要使用红黑树而不是AVL
  - 1、为什么不直接使用树
    - 大部分情况hashmap的数据量发生hash冲突的概率其实是很小的，此时使用链表是最佳选择
  - 2、为什么是红黑树？
    - AVL树是完全平衡二叉树，在节点插入时、删除时都会调整树结构来平衡，因此会消耗更多的时间
    - 虽然AVL的查找时间由于树高度更低而更快，但是插入和删除花费时间比红黑树更长，在hashmap这种情况下更适用红黑树
### LinkedHashMap
- 底层是散列表+红黑树+双向链表，父类是HashMap
- 允许为null，插入有序
- 非同步
- 提供插入顺序和访问顺序两种，访问顺序是符合LRU算法的，一般用于扩展(默认是插入顺序)
- 迭代与初始容量无关(迭代的是维护的双向链表)
- 大多使用HashMap的API，只不过在内部重写了某些方法，维护了双向链表

### TreeMap
- 底层是红黑树，保证了时间复杂度为log(n)
- 可以对其进行排序，使用Comparator或者Comparable
- 只要compare或者CompareTo认定该元素相等，那就相等
- 非同步
- 自然排序(手动排序)，元素不能为null
### ConcurrentHashMap
- 底层是散列表+红黑树，支持高并发操作
- key和value都不能为null
- 线程是安全的，利用CAS算法和部分操作上锁实现
- get方法是非阻塞，无锁的。重写Node类，通过volatile修饰next来实现每次获取都是最新设置的值
- 在高并发环境下，统计数据(计算size…等等)其实是无意义的，因为在下一时刻size值就变化了。
- 在 JDK1.7 中，ConcurrentHashMap 类采用了分段锁的思想，将 HashMap 进行切割，把 HashMap 中的哈希数组切分成小数组（Segment），每个小数组有 n 个 HashEntry 组成，其中 Segment 继承自ReentrantLock（可重入锁），从而实现并发控制！
- 从 jdk1.8 开始，ConcurrentHashMap 类取消了 Segment 分段锁，采用 CAS + synchronized来保证并发安全，数据结构跟 jdk1.8 中 HashMap 结构保持一致，都是 数组 + 链表（当链表长度大于8时，链表结构转为红黑树）结构。
- jdk1.8 中的 ConcurrentHashMap 中 synchronized 只锁定当前链表或红黑树的首节点，只要节点 hash 不冲突，就不会产生并发，相比 JDK1.7 的 ConcurrentHashMap 效率又提升了 N 倍！
### IdentityHashMap
- IdentityHashMap 从名字上看，感觉表示唯一的 HashMap，然后并不是，别被它的名称所欺骗哦。
- IdentityHashMap 的数据结构很简单，底层实际就是一个 Object 数组，在存储上并没有使用链表来存储，而是将 K 和 V 都存放在 Object 数组上。
- 当添加元素的时候，会根据 Key 计算得到散列位置，如果发现该位置上已经有改元素，直接进行新值替换；如果没有，直接进行存放。当元素个数达到一定阈值时，Object 数组会自动进行扩容处理。
- IdentityHashMap 的实现也不同于 HashMap，虽然也是数组，不过 IdentityHashMap 中没有用到链表，解决冲突的方式是计算下一个有效索引，并且将数据 key 和 value 紧挨着存入 map 中，即table[i]=key、table[i+1]=value；
- IdentityHashMap 允许key、value都为null，当key为null的时候，默认会初始化一个Object对象作为key；
### WeakHashMap
- WeakHashMap 是 Map 体系中一个很特殊的成员，它的特殊之处在于 WeakHashMap 里的元素可能会被 GC 自动删除，即使程序员没有显示调用 remove() 或者 clear() 方法。
- 换言之，当向 WeakHashMap 中添加元素的时候，再次遍历获取元素，可能发现它已经不见了
- WeakHashMap 的 key 使用了弱引用类型，在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。
- 不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。
- WeakHashMap 跟普通的 HashMap 不同，在存储数据时，key 被设置为弱引用类型，而弱引用类型在 java 中，可能随时被 jvm 的 gc 回收，所以再次通过获取对象时，可能得到空值，而 value 是在访问数组内容的时候，进行清除。
- 可能很多人觉得这样做很奇葩，其实不然，WeekHashMap 的这个特点特别适用于需要缓存的场景。
- 在缓存场景下，由于系统内存是有限的，不能缓存所有对象，可以使用 WeekHashMap 进行缓存对象，即使缓存丢失，也可以通过重新计算得到，不会造成系统错误。
- 比较典型的例子，Tomcat 中的 ConcurrentCache 类就使用了 WeekHashMap 来实现数据缓存。




