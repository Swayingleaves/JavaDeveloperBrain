* [场景设计](#场景设计)
    * [有A、B两个大文件，每个文件几十G，而内存只有4G，其中A文件存放学号+姓名，而B文件存放学号+分数，要求生成文件C，存放姓名和分数。怎么实现？](#有ab两个大文件每个文件几十g而内存只有4g其中a文件存放学号姓名而b文件存放学号分数要求生成文件c存放姓名和分数怎么实现)
    * [秒杀系统怎么设计](#秒杀系统怎么设计)
        * [秒杀存在的问题](#秒杀存在的问题)
        * [如何解决这些问题](#如何解决这些问题)
    * [唯一ID设计](#唯一id设计)
        * [UUID](#uuid)
        * [多台MySQL服务器](#多台mysql服务器)
        * [Twitter Snowflake](#twitter-snowflake)
        * [百度UidGenerator算法](#百度uidgenerator算法)
        * [美团Leaf算法](#美团leaf算法)
    * [产品上线出问题怎么定位错误](#产品上线出问题怎么定位错误)
    * [海量日志数据，提取出某日访问百度次数最多的那个IP。](#海量日志数据提取出某日访问百度次数最多的那个ip)
    * [给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？](#给定ab两个文件各存放50亿个url每个url各占64字节内存限制是4g让你找出ab文件共同的url)
        * [方案1](#方案1)
        * [方案2](#方案2)
    * [一般内存不足而需要分析的数据又很大的问题都可以使用分治的思想，将数据hash(x)%1000分为小文件再分别加载小文件到内存中处理即可](#一般内存不足而需要分析的数据又很大的问题都可以使用分治的思想将数据hashx1000分为小文件再分别加载小文件到内存中处理即可)
# 场景设计
## 有A、B两个大文件，每个文件几十G，而内存只有4G，其中A文件存放学号+姓名，而B文件存放学号+分数，要求生成文件C，存放姓名和分数。怎么实现？
- hash(学号)%1000，A到a0....a1000,B到b0~b1000
- 学号相同的人一定hash到相同序号的小文件
- 加载序号相同的小文件（比如：读取a2和b2）用map储存再按姓名+分数写入C即可
## 秒杀系统怎么设计
### 秒杀存在的问题
- 高并发、瞬间请求量极大
- 黄牛、黑客恶意请求
- 链接暴露问题
- 数据库压力问题
- 库存不足和超卖问题
### 如何解决这些问题
- 页面静态化
  - 秒杀活动的页面，大多数内容都是固定不变的，如商品名称，商品图片等等，可以对活动页面做静态化处理，减少访问服务端的请求。秒杀用户会分布在全国各地，有的在上海，有的在深圳，地域相差很远，网速也各不相同。为了让用户最快访问到活动页面，可以使用CDN（Content Delivery Network，内容分发网络）。CDN可以让用户就近获取所需内容。
- 按钮至灰控制
  - 秒杀活动开始前，按钮一般需要置灰的。只有时间到了，才能变得可以点击。这是防止，秒杀用户在时间快到的前几秒，疯狂请求服务器，然后秒杀时间点还没到，服务器就自己挂了。
- 服务单一职责
  - 我们都知道微服务设计思想，也就是把各个功能模块拆分，功能那个类似的放一起，再用分布式的部署方式。
  - 如用户登录相关的，就设计个用户服务，订单相关的就搞个订单服务，再到礼物相关的就搞个礼物服务等等。那么，秒杀相关的业务逻辑也可以放到一起，搞个秒杀服务，单独给它搞个秒杀数据库。
  - 服务单一职责有个好处：如果秒杀没抗住高并发的压力，秒杀库崩了，服务挂了，也不会影响到系统的其他服务。
- 秒杀链接加盐
  - 链接如果明文暴露的话，会有人获取到请求Url，提前秒杀了。因此，需要给秒杀链接加盐。可以把URL动态化，如通过MD5加密算法加密随机的字符串去做url。
- 限流
  - 一般有两种方式限流：nginx限流和redis限流。
  - 为了防止某个用户请求过于频繁，我们可以对同一用户限流；
  - 为了防止黄牛模拟几个用户请求，我们可以对某个IP进行限流；
  - 为了防止有人使用代理，每次请求都更换IP请求，我们可以对接口进行限流。
  - 为了防止瞬时过大的流量压垮系统，还可以使用阿里的Sentinel、Hystrix组件进行限流。
- 分布式锁
  - 可以使用redis分布式锁解决超卖问题。
  - 使用Redis的SET EX PX NX + 校验唯一随机值,再删除释放锁。
  - 为了更严谨，一般也是用lua脚本代替。lua脚本如下：
- MQ异步处理
  - 如果瞬间流量特别大，可以使用消息队列削峰，异步处理。用户请求过来的时候，先放到消息队列，再拿出来消费。
- 限流&降级&熔断
  - 限流，就是限制请求，防止过大的请求压垮服务器；
  - 降级，就是秒杀服务有问题了，就降级处理，不要影响别的服务；
  - 熔断，服务有问题就熔断，一般熔断降级是一起出现。
## 唯一ID设计
### UUID
### 多台MySQL服务器
- 既然MySQL可以产生自增ID，那么用多台MySQL服务器，能否组成一个高性能的分布式发号器呢？ 显然可以。
- 假设用8台MySQL服务器协同工作，第一台MySQL初始值是1，每次自增8，第二台MySQL初始值是2，每次自增8，依次类推。前面用一个 round-robin load balancer 挡着，每来一个请求，由 round-robin balancer 随机地将请求发给8台MySQL中的任意一个，然后返回一个ID
- 这个方法跟单台数据库比，缺点是ID是不是严格递增的，只是粗略递增的。不过这个问题不大，我们的目标是粗略有序，不需要严格递增。
### Twitter Snowflake
核心思想是：采用bigint（64bit）作为id生成类型，并将所占的64bit 划分成多段。
- ①1位标识：由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。
- ②41位时间截(毫秒级）：需要注意的是，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截）得到的值，这里的开始时间截，一般是指我们的id生成器开始使用的时间截，由我们的程序来指定。41位的毫秒时间截，可以使用69年（即T =（1L << 41）/（1000 60 60 24 365）= 69）。
- ③10位的数据机器位：包括5位数据中心标识Id（datacenterId）、5位机器标识Id(workerId)，最多可以部署1024个节点（即1 << 10 = 1024）。超过这个数量，生成的ID就有可能会冲突。
- ④12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒（同一机器，同一时间截）产生4096个ID序号（即1 << 12 = 4096）。
PS：全部结构标识（1+41+10+12=64）加起来刚好64位，刚好凑成一个Long型。
### 百度UidGenerator算法
### 美团Leaf算法
- 分段获取
- 即当号段消费到某个点时就异步的把下一个号段加载到内存中
## 产品上线出问题怎么定位错误
- 复现问题
## 大量并发查询用户商品信息，MySQL压力大查询慢，保证速度怎么优化方案
## 海量日志数据，提取出某日访问百度次数最多的那个IP。
- 可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址
- 对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址
- 可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；
## 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
### 方案1
- 遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。
- 遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
- 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。
### 方案2
如果允许有一定的误差，使用布隆过滤器
## 一般内存不足而需要分析的数据又很大的问题都可以使用分治的思想，将数据hash(x)%1000分为小文件再分别加载小文件到内存中处理即可